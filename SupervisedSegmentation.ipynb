{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of drive_run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6knrKMbe1xB",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhStspNwe7uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from unittest import mock\n",
        "import warnings\n",
        "from distutils.version import LooseVersion\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.editor import ImageSequenceClip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bld_zseP4720",
        "colab_type": "text"
      },
      "source": [
        "#Running Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvUHtINE27nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ON_DRIVE = True #@param {type: \"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgALjdlE-jtR",
        "colab_type": "text"
      },
      "source": [
        "#Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvkQ-Gh8wMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DLProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "\n",
        "# Download and extract pretrained vgg model if it doesn't exist\n",
        "def maybe_download_pretrained_vgg(data_dir):\n",
        "    vgg_filename = 'vgg.zip'\n",
        "    vgg_path = os.path.join(data_dir, 'vgg')\n",
        "    vgg_files = [\n",
        "        os.path.join(vgg_path, 'variables/variables.data-00000-of-00001'),\n",
        "        os.path.join(vgg_path, 'variables/variables.index'),\n",
        "        os.path.join(vgg_path, 'saved_model.pb')]\n",
        "\n",
        "    missing_vgg_files = [vgg_file for vgg_file in vgg_files if not os.path.exists(vgg_file)]\n",
        "    if missing_vgg_files:\n",
        "        # Clean vgg dir\n",
        "        if os.path.exists(vgg_path):\n",
        "            shutil.rmtree(vgg_path)\n",
        "        os.makedirs(vgg_path)\n",
        "\n",
        "        # Download vgg\n",
        "        print('Downloading pre-trained vgg model...')\n",
        "        with DLProgress(unit='B', unit_scale=True, miniters=1) as pbar:\n",
        "            urlretrieve(\n",
        "                'https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip',\n",
        "                os.path.join(vgg_path, vgg_filename),\n",
        "                pbar.hook)\n",
        "\n",
        "        # Extract vgg\n",
        "        print('Extracting model...')\n",
        "        zip_ref = zipfile.ZipFile(os.path.join(vgg_path, vgg_filename), 'r')\n",
        "        zip_ref.extractall(data_dir)\n",
        "        zip_ref.close()\n",
        "\n",
        "        # Remove zip file to save space\n",
        "        os.remove(os.path.join(vgg_path, vgg_filename))       \n",
        "    else:\n",
        "        print('Model found! No need to download.')\n",
        "\n",
        "\n",
        "# Generate function to create batches of training data\n",
        "def gen_batch_function(data_folder, image_shape):\n",
        "  \n",
        "    # Create batches of training data\n",
        "    def get_batches_fn(batch_size):\n",
        "        image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))\n",
        "        label_paths = {\n",
        "            re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
        "            for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
        "        background_color = np.array([255, 0, 0])\n",
        "\n",
        "        random.shuffle(image_paths)\n",
        "        for batch_i in range(0, len(image_paths), batch_size):\n",
        "            images = []\n",
        "            gt_images = []\n",
        "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
        "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
        "\n",
        "                image = np.array(Image.open(image_file).resize(image_shape))\n",
        "\n",
        "                gt_image = np.array(Image.open(gt_image_file).resize(image_shape))\n",
        "\n",
        "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
        "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "\n",
        "                images.append(image)\n",
        "                gt_images.append(gt_image)\n",
        "\n",
        "            yield np.array(images), np.array(gt_images)\n",
        "    return get_batches_fn\n",
        "\n",
        "\n",
        "# Generate test output using the test images\n",
        "def gen_test_output(sess, logits, keep_prob, image_pl, data_folder, image_shape):\n",
        "    for image_file in glob(os.path.join(data_folder, 'image_2', '*.png')):\n",
        "        image = np.array(Image.open(image_file).resize(image_shape))\n",
        "\n",
        "        im_softmax = sess.run(\n",
        "            [tf.nn.softmax(logits)],\n",
        "            {keep_prob: 1.0, image_pl: [image]})\n",
        "        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
        "        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
        "        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
        "        mask = Image.fromarray(mask, mode=\"RGBA\")\n",
        "        street_im = Image.fromarray(image)\n",
        "        street_im.paste(mask, box=None, mask=mask)\n",
        "\n",
        "        yield os.path.basename(image_file), np.array(street_im)\n",
        "\n",
        "\n",
        "def save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image):\n",
        "    # Make folder for current run\n",
        "    output_dir = os.path.join(runs_dir, str(time.time()))\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "    # Run NN on test images and save them to HD\n",
        "    print('Training Finished. Saving test images to: {}'.format(output_dir))\n",
        "    image_outputs = gen_test_output(\n",
        "        sess, logits, keep_prob, input_image, os.path.join(data_dir, 'data_road/testing'), image_shape)\n",
        "    for name, image in image_outputs:\n",
        "        out_image = Image.fromarray(image)\n",
        "        out_image.save(os.path.join(output_dir, name))\n",
        "\n",
        "# Generate test output using the test images\n",
        "def segment_single_image(sess, logits, keep_prob, input_image, image, image_shape):\n",
        "    image = np.array(image.resize(image_shape))\n",
        "\n",
        "    im_softmax = sess.run([tf.nn.softmax(logits)],\n",
        "                          {keep_prob: 1.0, input_image: [image]\n",
        "                          })\n",
        "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
        "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
        "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
        "    mask = Image.fromarray(mask, mode=\"RGBA\")\n",
        "        \n",
        "    street_im = Image.fromarray(image)        \n",
        "    street_im.paste(mask, box=None, mask=mask)\n",
        "\n",
        "    return np.array(street_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgRmu9Mx-nYp",
        "colab_type": "text"
      },
      "source": [
        "#Testing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcuFeymz-jDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_safe(func):\n",
        "    \"\"\"\n",
        "    Isolate tests\n",
        "    \"\"\"\n",
        "    def func_wrapper(*args):\n",
        "        with tf.Graph().as_default():\n",
        "            result = func(*args)\n",
        "        print('Tests Passed')\n",
        "        return result\n",
        "\n",
        "    return func_wrapper\n",
        "\n",
        "\n",
        "def _prevent_print(function, params):\n",
        "    sys.stdout = open(os.devnull, \"w\")\n",
        "    function(**params)\n",
        "    sys.stdout = sys.__stdout__\n",
        "\n",
        "\n",
        "def _assert_tensor_shape(tensor, shape, display_name):\n",
        "    assert tf.assert_rank(tensor, len(shape), message='{} has wrong rank'.format(display_name))\n",
        "\n",
        "    tensor_shape = tensor.get_shape().as_list() if len(shape) else []\n",
        "\n",
        "    wrong_dimension = [ten_dim for ten_dim, cor_dim in zip(tensor_shape, shape)\n",
        "                       if cor_dim is not None and ten_dim != cor_dim]\n",
        "    assert not wrong_dimension, \\\n",
        "        '{} has wrong shape.  Found {}'.format(display_name, tensor_shape)\n",
        "\n",
        "\n",
        "# Mock an attribute.  Restore attribute when exiting scope.\n",
        "class TmpMock(object):\n",
        "    def __init__(self, module, attrib_name):\n",
        "        self.original_attrib = deepcopy(getattr(module, attrib_name))\n",
        "        setattr(module, attrib_name, mock.MagicMock())\n",
        "        self.module = module\n",
        "        self.attrib_name = attrib_name\n",
        "\n",
        "    def __enter__(self):\n",
        "        return getattr(self.module, self.attrib_name)\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        setattr(self.module, self.attrib_name, self.original_attrib)\n",
        "\n",
        "\n",
        "@test_safe\n",
        "def test_load_vgg(load_vgg, tf_module):\n",
        "    with TmpMock(tf_module.saved_model.loader, 'load') as mock_load_model:\n",
        "        vgg_path = ''\n",
        "        sess = tf.Session()\n",
        "        test_input_image = tf.placeholder(tf.float32, name='image_input')\n",
        "        test_keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "        test_vgg_layer3_out = tf.placeholder(tf.float32, name='layer3_out')\n",
        "        test_vgg_layer4_out = tf.placeholder(tf.float32, name='layer4_out')\n",
        "        test_vgg_layer7_out = tf.placeholder(tf.float32, name='layer7_out')\n",
        "\n",
        "        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
        "\n",
        "        assert mock_load_model.called, \\\n",
        "            'tf.saved_model.loader.load() not called'\n",
        "        assert mock_load_model.call_args == mock.call(sess, ['vgg16'], vgg_path), \\\n",
        "            'tf.saved_model.loader.load() called with wrong arguments.'\n",
        "\n",
        "        assert input_image == test_input_image, 'input_image is the wrong object'\n",
        "        assert keep_prob == test_keep_prob, 'keep_prob is the wrong object'\n",
        "        assert vgg_layer3_out == test_vgg_layer3_out, 'layer3_out is the wrong object'\n",
        "        assert vgg_layer4_out == test_vgg_layer4_out, 'layer4_out is the wrong object'\n",
        "        assert vgg_layer7_out == test_vgg_layer7_out, 'layer7_out is the wrong object'\n",
        "\n",
        "\n",
        "@test_safe\n",
        "def test_layers(layers):\n",
        "    num_classes = 2\n",
        "    vgg_layer3_out = tf.placeholder(tf.float32, [None, None, None, 256])\n",
        "    vgg_layer4_out = tf.placeholder(tf.float32, [None, None, None, 512])\n",
        "    vgg_layer7_out = tf.placeholder(tf.float32, [None, None, None, 4096])\n",
        "    layers_output = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
        "\n",
        "    _assert_tensor_shape(layers_output, [None, None, None, num_classes], 'Layers Output')\n",
        "\n",
        "\n",
        "@test_safe\n",
        "def test_optimize(optimize):\n",
        "    num_classes = 2\n",
        "    shape = [2, 3, 4, num_classes]\n",
        "    layers_output = tf.Variable(tf.zeros(shape))\n",
        "    correct_label = tf.placeholder(tf.float32, [None, None, None, num_classes])\n",
        "    learning_rate = tf.placeholder(tf.float32)\n",
        "    logits, train_op, cross_entropy_loss, decaying_learning_rate = optimize(layers_output, correct_label, learning_rate, num_classes)\n",
        "    #logits, train_op, cross_entropy_loss = optimize(layers_output, correct_label, learning_rate, num_classes)\n",
        "\n",
        "    _assert_tensor_shape(logits, [2*3*4, num_classes], 'Logits')\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run([train_op, decaying_learning_rate], {correct_label: np.arange(np.prod(shape)).reshape(shape), learning_rate: 10})\n",
        "        test, loss = sess.run([layers_output, cross_entropy_loss], {correct_label: np.arange(np.prod(shape)).reshape(shape)})\n",
        "\n",
        "    assert test.min() != 0 or test.max() != 0, 'Training operation not changing weights.'\n",
        "\n",
        "\n",
        "@test_safe\n",
        "def test_train_nn(train_nn):\n",
        "    epochs = 1\n",
        "    batch_size = 2\n",
        "\n",
        "    def get_batches_fn(batach_size_parm):\n",
        "        shape = [batach_size_parm, 2, 3, 3]\n",
        "        return np.arange(np.prod(shape)).reshape(shape)\n",
        "\n",
        "    train_op = tf.constant(0)\n",
        "    cross_entropy_loss = tf.constant(10.11)\n",
        "    input_image = tf.placeholder(tf.float32, name='input_image')\n",
        "    correct_label = tf.placeholder(tf.float32, name='correct_label')\n",
        "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
        "    decaying_learning_rate = tf.convert_to_tensor(0.0, dtype=tf.float32, name='decaying_learning_rate')\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        parameters = {\n",
        "            'sess': sess,\n",
        "            'epochs': epochs,\n",
        "            'batch_size': batch_size,\n",
        "            'get_batches_fn': get_batches_fn,\n",
        "            'train_op': train_op,\n",
        "            'cross_entropy_loss': cross_entropy_loss,\n",
        "            'input_image': input_image,\n",
        "            'correct_label': correct_label,\n",
        "            'keep_prob': keep_prob,\n",
        "            'learning_rate': learning_rate,\n",
        "            'decaying_learning_rate': decaying_learning_rate}\n",
        "        # _prevent_print(train_nn, parameters)\n",
        "        train_nn(**parameters)\n",
        "\n",
        "@test_safe\n",
        "def test_for_kitti_dataset(data_dir):\n",
        "    kitti_dataset_path = os.path.join(data_dir, 'data_road')\n",
        "    training_labels_count = len(glob(os.path.join(kitti_dataset_path, 'training/gt_image_2/*_road_*.png')))\n",
        "    training_images_count = len(glob(os.path.join(kitti_dataset_path, 'training/image_2/*.png')))\n",
        "    testing_images_count = len(glob(os.path.join(kitti_dataset_path, 'testing/image_2/*.png')))\n",
        "\n",
        "    assert not (training_images_count == training_labels_count == testing_images_count == 0),\\\n",
        "        'Kitti dataset not found. Extract Kitti dataset in {}'.format(kitti_dataset_path)\n",
        "    assert training_images_count == 289, 'Expected 289 training images, found {} images.'.format(training_images_count)\n",
        "    assert training_labels_count == 289, 'Expected 289 training labels, found {} labels.'.format(training_labels_count)\n",
        "    assert testing_images_count == 290, 'Expected 290 testing images, found {} images.'.format(testing_images_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeXOvT51-t_2",
        "colab_type": "text"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1THQImy-tp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check TensorFlow Version\n",
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))\n",
        "\n",
        "# Check for a GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "DECAY_RATE = 0.90\n",
        "DECAY_AFTER_N_STEPS = 50\n",
        "KEEP_PROB = 0.5\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 5\n",
        "CLASSES = 2\n",
        "IMAGE_SHAPE = (576, 160)\n",
        "L2_REG = 0.001\n",
        "STD_DEV = 0.01\n",
        "\n",
        "DATA_DIR = './data'\n",
        "VIDEO_DIR = './video'\n",
        "\n",
        "if ON_DRIVE:\n",
        "  DATA_DIR = './drive/My Drive/data'\n",
        "  VIDEO_DIR = './drive/My Drive/video'\n",
        "\n",
        "\n",
        "# Load Pretrained VGG Model into TensorFlow.\n",
        "def load_vgg(sess, vgg_path):\n",
        "\n",
        "    vgg_tag = 'vgg16'\n",
        "    vgg_input_tensor_name = 'image_input:0'\n",
        "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
        "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
        "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
        "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
        "    \n",
        "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
        "    graph = tf.get_default_graph()\n",
        "    input_image = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
        "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
        "    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name) # pooled layer 3\n",
        "    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name) # pooled layer 4\n",
        "    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name) # convolved layer 7\n",
        "    \n",
        "    return input_image, keep_prob, layer3_out, layer4_out, layer7_out\n",
        "test_load_vgg(load_vgg, tf)\n",
        "\n",
        "\n",
        "# Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
        "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
        "  \n",
        "    # layer 7 1x1 convolution to conserve spatial information\n",
        "    layer7_1x1 = tf.layers.conv2d(vgg_layer7_out, num_classes, 1, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "    \n",
        "    # layer 7 1x1 convolution upsampled to reverse the convolution operation\n",
        "    layer7_upsampled = tf.layers.conv2d_transpose(layer7_1x1, num_classes, 4, 2, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "    \n",
        "    # layer 4 1x1 convolution to conserve spatial information\n",
        "    layer4_1x1 = tf.layers.conv2d(vgg_layer4_out, num_classes, 1, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "    \n",
        "    # Skip connection between convolved layer 4 & convolved + upsampled layer 7 to retain the original context\n",
        "    layer4_7_skip_connection = tf.add(layer7_upsampled, layer4_1x1)\n",
        "    \n",
        "    # Upscaling again in preparation for creating the skip connection between layer 7 & layer 3\n",
        "    layer7_final = tf.layers.conv2d_transpose(layer4_7_skip_connection, num_classes, 4, 2, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "    \n",
        "    # layer 3 1x1 convolution to conserve spatial information\n",
        "    layer3_1x1 = tf.layers.conv2d(vgg_layer3_out, num_classes, 1, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "    \n",
        "    # Skip connection between convolved layer 3 & upsampled layer 7 \n",
        "    layer3_7_skip_connection = tf.add(layer3_1x1, layer7_final)\n",
        "    \n",
        "    # final layer upscaling\n",
        "    layer_last = tf.layers.conv2d_transpose(layer3_7_skip_connection, num_classes, 16, 8, padding='same',\n",
        "                             kernel_initializer= tf.random_normal_initializer(stddev=STD_DEV),\n",
        "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(L2_REG))\n",
        "\n",
        "    return layer_last\n",
        "test_layers(layers)\n",
        "\n",
        "# Build the TensorFLow loss and optimizer operations.\n",
        "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
        "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
        "    labels = tf.reshape(correct_label, (-1, num_classes))\n",
        "    \n",
        "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "    \n",
        "    # Apply decaying learning rate i.e. the learning rate decreases as the epochs increase\n",
        "    global_step = tf.Variable(0, trainable=False) \n",
        "    initial_learning_rate = learning_rate\n",
        "    decaying_learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, DECAY_AFTER_N_STEPS, DECAY_RATE, staircase=True)\n",
        "    \n",
        "    # Optimizer for reducing loss\n",
        "    optimizer = tf.train.AdamOptimizer(decaying_learning_rate)\n",
        "    \n",
        "    train_op = optimizer.minimize(cross_entropy_loss, global_step=global_step)\n",
        "    \n",
        "    return logits, train_op, cross_entropy_loss, decaying_learning_rate\n",
        "test_optimize(optimize)\n",
        "\n",
        "\n",
        "# Train neural network and print out the loss during training.\n",
        "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
        "             correct_label, keep_prob, learning_rate, decaying_learning_rate):\n",
        "    epoch_loss = {}\n",
        "    batch_loss = []\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        print('Epoch: {} START...'.format(epoch + 1))\n",
        "        batch_counter = 1\n",
        "        for image, label in get_batches_fn(batch_size):\n",
        "            _, loss, decaying_rate = sess.run([train_op, cross_entropy_loss, decaying_learning_rate],\n",
        "                                              feed_dict={\n",
        "                                                      input_image: image,\n",
        "                                                      correct_label: label,\n",
        "                                                      keep_prob: KEEP_PROB,\n",
        "                                                      learning_rate: LEARNING_RATE\n",
        "                                                      })  \n",
        "            print(\"  Batch {} >>> Loss = {:.4f}, Learning Rate = {:.6f}\".format(batch_counter, loss, decaying_rate))\n",
        "            batch_loss.append(loss)\n",
        "            batch_counter += 1\n",
        "        end_time = time.time()\n",
        "        elapsed = end_time - start_time\n",
        "        hours = elapsed//3600\n",
        "        minutes = (elapsed%3600)//60\n",
        "        seconds = (elapsed%3600)%60\n",
        "        print(\"Epoch: {} END. Time taken: {:.0f} hours {:.0f} minutes {:.0f} seconds\\n\".format(epoch + 1, hours, minutes, seconds))\n",
        "        epoch_loss[epoch] = np.average(batch_loss)\n",
        "    return epoch_loss\n",
        "test_train_nn(train_nn)\n",
        "\n",
        "def run():\n",
        "    num_classes = CLASSES\n",
        "    image_shape = IMAGE_SHAPE\n",
        "    data_dir = DATA_DIR\n",
        "    runs_dir = './runs'\n",
        "    if ON_DRIVE:\n",
        "      runs_dir = './drive/My Drive/runs'\n",
        "    test_for_kitti_dataset(data_dir)\n",
        "\n",
        "    # Download pretrained vgg model\n",
        "    maybe_download_pretrained_vgg(data_dir)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        # Path to vgg model\n",
        "        vgg_path = os.path.join(data_dir, 'vgg')\n",
        "        # Create function to get batches\n",
        "        get_batches_fn = gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
        "        \n",
        "        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n",
        "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
        "\n",
        "        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
        "\n",
        "        nn_last_layer = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
        "\n",
        "        logits, train_op, cross_entropy_loss, decaying_learning_rate = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n",
        "        start_time = time.time()\n",
        "        \n",
        "        epoch_loss = train_nn(sess, EPOCHS, BATCH_SIZE, get_batches_fn, train_op, \n",
        "                              cross_entropy_loss, input_image, correct_label, keep_prob, learning_rate, decaying_learning_rate)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        elapsed = end_time - start_time\n",
        "        hours = elapsed//3600\n",
        "        minutes = (elapsed%3600)//60\n",
        "        seconds = (elapsed%3600)%60\n",
        "        print(\"Training time: {:.0f} hours {:.0f} minutes {:.0f} seconds\".format(hours, minutes, seconds))     \n",
        "        \n",
        "        log_file_path = './' + str(EPOCHS) + '_log.txt'\n",
        "        log_file = open(log_file_path, 'w') \n",
        "        log_file.write('Epoch,Loss\\n')\n",
        "        for key in epoch_loss.keys():\n",
        "            log_file.write('{},{}\\n'.format(key, epoch_loss[key]))\n",
        "        log_file.close()\n",
        "        \n",
        "        start_time = time.time()\n",
        "        # Save inference data using helper.save_inference_samples\n",
        "        save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed = end_time - start_time\n",
        "        hours = elapsed//3600\n",
        "        minutes = (elapsed%3600)//60\n",
        "        seconds = (elapsed%3600)%60\n",
        "        print(\"Inference time: {:.0f} hours {:.0f} minutes {:.0f} seconds\".format(hours, minutes, seconds))\n",
        "        \n",
        "        start_time = time.time()\n",
        "        processed_frames = []\n",
        "        # Load video \n",
        "        video_clip = VideoFileClip(VIDEO_DIR + '/solidWhiteRight.mp4')\n",
        "        frame_counter = 1;\n",
        "        for frame in video_clip.iter_frames():\n",
        "            processed_frame = segment_single_image(sess, logits, keep_prob, input_image, frame, image_shape)\n",
        "            # Collect processed frame\n",
        "            processed_frames.append(processed_frame)\n",
        "            print(\"Frame {} processed\".format(frame_counter))\n",
        "            frame_counter += 1 \n",
        "        # Stitcha all frames to get the video\n",
        "        processed_video = ImageSequenceClip(processed_frames, fps=video_clip.fps)\n",
        "        processed_video.write_videofile(VIDEO_DIR + '/solidWhiteRight_processed.mp4', audio=False)\n",
        "        print(\"Processed video written to {} directory\".format(VIDEO_DIR))\n",
        "        end_time = time.time()\n",
        "        elapsed = end_time - start_time\n",
        "        hours = elapsed//3600\n",
        "        minutes = (elapsed%3600)//60\n",
        "        seconds = (elapsed%3600)%60\n",
        "        print(\"Video processing time: {:.0f} hours {:.0f} minutes {:.0f} seconds\".format(hours, minutes, seconds))\n",
        "run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}